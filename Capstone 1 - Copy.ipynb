{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursera Week 5 Assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries used for the asignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sb006047682\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\sb006047682\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.8)\n",
      "Requirement already satisfied: bs4 in c:\\users\\sb006047682\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sb006047682\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from bs4) (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\sb006047682\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.8)\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::altair==4.0.1=py_0\n",
      "  - defaults/noarch::autovizwidget==0.12.7=py_0\n",
      "  - defaults/win-64::bokeh==1.1.0=py36_0\n",
      "  - defaults/win-64::bottleneck==1.2.1=py36h452e1ab_1\n",
      "  - defaults/win-64::cupy==4.1.0=py36h137e5fc_0\n",
      "  - defaults/win-64::datashape==0.5.4=py36_1\n",
      "  - defaults/win-64::descartes==1.1.0=py36_0\n",
      "  - conda-forge/noarch::folium==0.5.0=py_0\n",
      "  - defaults/win-64::gdal==2.3.3=py36hdf43c64_0\n",
      "  - defaults/win-64::h5py==2.9.0=py36h5e291fa_0\n",
      "  - conda-forge/noarch::hdijupyterutils==0.12.9=py_0\n",
      "  - conda-forge/win-64::mkl_fft==1.0.13=py36hfa6e2cd_1\n",
      "  - conda-forge/win-64::pandas==1.0.1=py36he350917_0\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch/noarch::snuggs==1.4.3=py_0\n",
      "  - conda-forge/noarch::vincent==0.4.4=py_1\n",
      "\n",
      "Warning: >10 possible package resolutions (only showing differing packages):\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-applehelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-devhelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::xlsxwriter-1.1.8-py_0\n",
      "  - defaults/noarch::xlsxwriter-1.1.8-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-applehelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-devhelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0\n",
      "  - defaults/noarch::sphinxcontrib-applehelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-devhelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::xlsxwriter-1.1.8-py_0\n",
      "  - defaults/noarch::sphinxcontrib-applehelp-1.0.1-py_0, defaults/noarch::xlsxwriter-1.1.8-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-devhelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0\n",
      "  - defaults/noarch::sphinxcontrib-applehelp-1.0.1-py_0, defaults/noarch::sphinxcontrib-devhelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::xlsxwriter-1.1.8-py_0\n",
      "  - defaults/noarch::sphinxcontrib-applehelp-1.0.1-py_0, defaults/noarch::sphinxcontrib-devhelp-1.0.1-py_0, defaults/noarch::xlsxwriter-1.1.8-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0\n",
      "  - defaults/noarch::sphinxcontrib-devhelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-applehelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::xlsxwriter-1.1.8-py_0\n",
      "  - defaults/noarch::sphinxcontrib-devhelp-1.0.1-py_0, defaults/noarch::xlsxwriter-1.1.8-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-applehelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0\n",
      "  - defaults/noarch::sphinxcontrib-devhelp-1.0.1-py_0, defaults/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-applehelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::xlsxwriter-1.1.8-py_0\n",
      "  - defaults/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-applehelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::sphinxcontrib-devhelp-1.0.1-py_0, https://repo.anaconda.com/pkgs/main/noarch/noarch::xlsxwriter-1.1.8-py_0\n",
      "  ... and othersdone\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\sB006047682\\AppData\\Local\\Continuum\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - folium=0.5.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    numpy-1.16.3               |   py36h19fb1c0_0          49 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:          49 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  matplotlib         conda-forge/win-64::matplotlib-3.1.1-py36_1\n",
      "  matplotlib-base    conda-forge/win-64::matplotlib-base-3.1.1-py36h2852a4a_1\n",
      "  numpy              pkgs/main/win-64::numpy-1.16.3-py36h19fb1c0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "numpy-1.16.3         | 49 KB     |            |   0% \n",
      "numpy-1.16.3         | 49 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Rolling back transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR conda.core.link:_execute(700): An error occurred while installing package 'conda-forge::matplotlib-base-3.1.1-py36h2852a4a_1'.\n",
      "\n",
      "[Errno 13] Permission denied: 'C:\\\\Users\\\\sB006047682\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Lib\\\\site-packages\\\\matplotlib\\\\_contour.cp36-win_amd64.pyd'\n",
      "()\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KMeans'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8d03fca048e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# import k-means from clustering stage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m \u001b[1;31m# library to handle requests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'KMeans'"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "!pip install beautifulsoup4\n",
    "!pip install bs4\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes \n",
    "import folium # map rendering library\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Toronto Postal Code information from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 HTML Formatting Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(data_arr_list):\n",
    "    tags = [\"<td>\", \"</td>\", \"\\n\", \"td>\" , \"</td\", \"]]\"]\n",
    "    for i in range(0, len(data_arr_list)):\n",
    "        for j in range(0, len(tags)):\n",
    "            if str(tags[j]) in str(data_arr_list[i]):\n",
    "                data_arr_list[i] = data_arr_list[i].replace(tags[j], \"\")\n",
    "                if 'title=\"' in str(data_arr_list[i]):\n",
    "                    data_arr_list[i] = str(data_arr_list[i]).split('title=\"')[1].split('\">')[0]\n",
    "    \n",
    "    return (data_arr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_postal(data_arr_list):\n",
    "\n",
    "    #Compare the postal code to the next one in order\n",
    "    for i in range (0, len(data_arr_list)-3, 3):\n",
    "\n",
    "        if str(data_arr_list[i]) == str(data_arr_list[i+3]):\n",
    "            #Add to the current postal code\n",
    "            if str(data_arr_list[i+4]) not in data_arr_list[i+1]:\n",
    "                data_arr_list[i+1] = str(data_arr_list[i+1]) + \", \" + str(data_arr_list[i+4])\n",
    "            if str(data_arr_list[i+5]) not in data_arr_list[i+2]:\n",
    "                data_arr_list[i+2] = str(data_arr_list[i+2]) + \", \" + str(data_arr_list[i+5])\n",
    "            \n",
    "            #Remove old entry(s)\n",
    "            del(data_arr_list[i+3])\n",
    "            del(data_arr_list[i+3])\n",
    "            del(data_arr_list[i+3])\n",
    "            \n",
    "            data_arr_list = compile_postal(data_arr_list)\n",
    "            \n",
    "            break\n",
    "            \n",
    "    return data_arr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Drop borough rows that are N/A\n",
    "\n",
    "def drop_na_borough(data_arr_list):\n",
    "\n",
    "    for i in range (1, len(data_arr_list)-1, 3):\n",
    "        if str(data_arr_list[i]) == 'Not assigned':\n",
    "            \n",
    "            #Remove the row\n",
    "            del(data_arr_list[i-1])\n",
    "            del(data_arr_list[i-1])\n",
    "            del(data_arr_list[i-1])\n",
    "            \n",
    "            data_arr_list = drop_na_borough(data_arr_list)\n",
    "            break\n",
    "            \n",
    "    return data_arr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborhood_borough(data_arr_list):\n",
    "    \n",
    "    for i in range (2, len(data_arr_list), 3):\n",
    "        if str(data_arr_list[i]) == 'Not assigned':\n",
    "            \n",
    "            data_arr_list[i] = str(data_arr_list[i-1])\n",
    "            data_arr_list = neighborhood_borough(data_arr_list)\n",
    "            \n",
    "            break\n",
    "            \n",
    "    return data_arr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Identify Postal Code Information from the Wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the url\n",
    "quote_page = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\n",
    "\n",
    "# query the website and return the html to the variable ‘page’\n",
    "page = urlopen(quote_page)\n",
    "\n",
    "# parse the html using beautiful soup and store in variable `soup`\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "#Define array to hold all of the data points\n",
    "data_arr = []\n",
    "\n",
    "#Get the first table in the html\n",
    "data = soup.findAll('table')\n",
    "\n",
    "#assign the cells to the array\n",
    "for row in data:\n",
    "    for item in row.findAll('td'):\n",
    "        if \"<td>\" in str(item):\n",
    "            data_arr.append(str(item))\n",
    "\n",
    "#Remove the last element in the list as it is invalid\n",
    "data_arr.pop()            \n",
    "\n",
    "#Clean up the tags and data points\n",
    "\n",
    "#Remove HTML tags\n",
    "data_arr = remove_tags(data_arr)\n",
    "\n",
    "#Compile postal codes\n",
    "data_arr = compile_postal(data_arr)\n",
    "\n",
    "#Drop Not assigned boroughs\n",
    "data_arr = drop_na_borough(data_arr)\n",
    "\n",
    "#Assign borough to n/a neighborhoods\n",
    "data_arr = neighborhood_borough(data_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Pandas Dataframe with Toronto data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Display the Dataframe with Wikipedia Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary\n",
    "toronto_dict = {'Postal_Code':data_arr[0::3], 'Borough': data_arr[1::3], \n",
    "                                     'Neighborhood':data_arr[2::3] }\n",
    "\n",
    "#Pandas Data frame\n",
    "toronto_df = pd.DataFrame.from_dict(toronto_dict)\n",
    "\n",
    "#*********Uncomment these lines to focus only on those boroughs in Toronto - containing the word Toronto*********#\n",
    "#toronto_df = toronto_df[toronto_df['Borough'].str.contains(\"Toronto\")==True]\n",
    "#toronto_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Print the shape of the new frame and display the first 5 rows\n",
    "print(toronto_df.shape)\n",
    "\n",
    "toronto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Add location information to the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the Latitude and Longitude columns to the table and initialize with placeholder information\n",
    "toronto_df['Latitude'] = 'Not Set'\n",
    "toronto_df['Longitude'] = 'Not Set'\n",
    "\n",
    "#Open file containing the geospacial coordinates for Toronto\n",
    "with open('Geospatial_Coordinates.csv', 'r') as csvfile:\n",
    "    geo_reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in geo_reader:\n",
    "        #Find the postal code in the fame and add coordinates\n",
    "        toronto_df.loc[toronto_df['Postal_Code'] == str(row[0]), \"Latitude\"] = str(row[1])\n",
    "        toronto_df.loc[toronto_df['Postal_Code'] == str(row[0]), \"Longitude\"] = str(row[2])\n",
    "        \n",
    "#Set type to numeric\n",
    "toronto_df['Latitude'] = pd.to_numeric(toronto_df['Latitude'])\n",
    "toronto_df['Longitude'] = pd.to_numeric(toronto_df['Longitude'])\n",
    "\n",
    "\n",
    "toronto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Add population information to the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the population columns to the table and initialize with placeholder information\n",
    "toronto_df['Population'] = 'Not Set'\n",
    "\n",
    "#Open file containing the geospacial coordinates for Toronto\n",
    "with open('Canada Population.csv', 'r') as csvfile:\n",
    "    geo_reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in geo_reader:\n",
    "        #Find the postal code in the fame and add coordinates\n",
    "        toronto_df.loc[toronto_df['Postal_Code'] == str(row[0]), \"Population\"] = str(row[4])\n",
    "\n",
    "#For those without population data, remove them, from the dataframe\n",
    "toronto_df = toronto_df[toronto_df['Population'].str.contains(\"Not Set\")==False]\n",
    "toronto_df.reset_index(drop=True, inplace=True)\n",
    "toronto_df['Population'] = pd.to_numeric(toronto_df['Population'])\n",
    "\n",
    "toronto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Remove underpopulated postal codes from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with < 25000 population\n",
    "clip = 20000\n",
    "\n",
    "toronto_df = toronto_df[toronto_df['Population'].ge(25000)]\n",
    "toronto_df ['Population'] = pd.to_numeric(toronto_df ['Population'])\n",
    "toronto_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "toronto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get nearby venues from Foursquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Foursquare credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'B0K442ZABARQK0HVKEPBPEPLSDNBXTGUQ2PEOEU0AMDN4YAJ' # your Foursquare ID\n",
    "CLIENT_SECRET = 'TOTW50KQOA02KK343155NVTYIGO4XW3PP2SDNYZEBZYV4Z3D' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Foursquare function to pull nearby values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cognitive Class.ai\n",
    "## Segmenting and Clustering Neighborhoods in New York City\n",
    "## Note: This function is taken from : https://labs.cognitiveclass.ai/tools/jupyterlab/lab/tree/labs/DP0701EN/DP0701EN-3-3-2-Neighborhoods-New-York-py-v1.0.ipynb\n",
    "## I do not take credit for writing the below function\n",
    "## I have used this function and made changes where nessesary for use in this project\n",
    "\n",
    "#This function will get the near-by venues of a location using coordinates\n",
    "\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius):\n",
    "    \n",
    "    venues_list=[]\n",
    "    remove = []\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        #Log postal codees without nearby addresses \n",
    "        if not results:\n",
    "            remove.append(name)\n",
    "\n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Postal_Code', \n",
    "                  'Postal_Latitude', \n",
    "                  'Postal_Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue_Latitude', \n",
    "                  'Venue_Longitude', \n",
    "                  'Venue_Category']\n",
    "    \n",
    "    return(nearby_venues, remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Get venues and add to the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Radius of 750m and a limit of 100 venues\n",
    "radius = 750\n",
    "LIMIT = 100\n",
    "\n",
    "\n",
    "#Get the venues near Toronto postal codes\n",
    "toronto_venues,remove = getNearbyVenues(names=toronto_df['Postal_Code'],\n",
    "                                   latitudes=toronto_df['Latitude'],\n",
    "                                   longitudes=toronto_df['Longitude'],\n",
    "                                   radius = radius\n",
    "                                  )\n",
    "\n",
    "#Remove those postal codes with no nearby venues\n",
    "for item in remove:\n",
    "    indexNames = toronto_df[ toronto_df['Postal_Code'] == item ].index\n",
    "    # Delete these row indexes from dataFrame\n",
    "    toronto_df.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Examine the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the dataframe and the first 5 rows\n",
    "toronto_venues.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine how many unique categories there are \n",
    "print('There are {} uniques categories.'.format(len(toronto_venues['Venue_Category'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the categories:\n",
    "for i in range (0, len(toronto_venues['Venue_Category'].unique())):\n",
    "    print(toronto_venues['Venue_Category'].unique()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Assign points to the venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define function to determine point value for venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(venue):\n",
    "    venue = venue.lower() \n",
    "    venue = venue.split()\n",
    "    value = 1\n",
    "    \n",
    "    two_points = [\"bar\", \"pub\", \"bus\", \"transport\", \"rail\", \"plane\" \\\n",
    "                        , \"boat\", \"airport\", \"ferry\", \"station\"]\n",
    "    three_points = [\"church\", \"club\", \"hotel\", \"hostel\", \"community\", \\\n",
    "                        \"museaum\", \"court\", \"field\", \"stadium\", \"sport\", \\\n",
    "                        \"playground\", \"theatre\", \"gallery\", \"center\", \"hall\", \\\n",
    "                        \"event\", \"park\"]\n",
    "    four_points = [\"store\", \"shop\", \"mall\", \"plaza\", \"market\", \"grocery\"]\n",
    "    five_points = [\"office\", \"school\"]\n",
    "    minus_two = [\"restaurant\", \"joint\", \"diner\", \"food\"]\n",
    "    minus_ten = [\"adult\"]\n",
    "    \n",
    "    for word in venue:\n",
    "        if word in two_points:\n",
    "            if 2 > value:\n",
    "                value = 2\n",
    "\n",
    "        if word in three_points:\n",
    "            if 3 > value:\n",
    "                value = 3\n",
    "\n",
    "        if word in four_points:\n",
    "            if 4 > value:\n",
    "                value = 4\n",
    "\n",
    "        if word in five_points:\n",
    "            if 5 > value:\n",
    "                value = 5\n",
    "\n",
    "        if word in minus_two:\n",
    "            if value > -2:\n",
    "                value = -2  \n",
    "\n",
    "        if word in minus_ten:\n",
    "            if value > -10:    \n",
    "                value = -10\n",
    "    \n",
    "    return (value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Add column to dataframe to record points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the points column to the df\n",
    "toronto_venues['Point_Value'] = \"Not Set\"\n",
    "\n",
    "#Get the point value for each venue\n",
    "for i in range(0, len(toronto_venues)):\n",
    "    toronto_venues[\"Point_Value\"][i] = get_points(str(toronto_venues[\"Venue_Category\"][i]))\n",
    "    \n",
    "\n",
    "toronto_venues['Point_Value'] = pd.to_numeric(toronto_venues['Point_Value'])\n",
    "\n",
    "toronto_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Add sum of venue points to the postal code in toronto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the points column to the toronto_df\n",
    "toronto_df['Point_Value'] = \"Not Set\"\n",
    "\n",
    "#Sum the venues points for each postal code and add to toronto_df\n",
    "for i in range(0, len(toronto_df)):\n",
    "    toronto_df[\"Point_Value\"][i] = toronto_venues[ toronto_venues['Postal_Code'] \\\n",
    "                                           == toronto_df[\"Postal_Code\"][i]][\"Point_Value\"].sum() \n",
    "\n",
    "toronto_df['Point_Value'] = pd.to_numeric(toronto_df['Point_Value'])\n",
    "\n",
    "toronto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Sort the df and analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the df in descending order\n",
    "toronto_df = toronto_df.sort_values(by='Point_Value', ascending=False)\n",
    "\n",
    "#display the df\n",
    "toronto_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function regplot to make a scatterplot\n",
    "sns.regplot(x=toronto_df[\"Population\"], y=toronto_df[\"Point_Value\"], fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Normalize the population and scale the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "xmax = toronto_df['Population'].max().astype(int)\n",
    "xmin = toronto_df['Population'].min().astype(int)\n",
    "\n",
    "\n",
    "for i in range(0, len(toronto_df)):\n",
    "    toronto_df[\"Point_Value\"][i] = (1-(toronto_df['Population'][i].astype(float) - xmin)/(xmax-xmin))*toronto_df[\"Point_Value\"][i]\n",
    "\n",
    "#Sort the df in descending order\n",
    "toronto_df = toronto_df.sort_values(by='Point_Value', ascending=False)\n",
    "\n",
    "#Reset index\n",
    "toronto_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "toronto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the function regplot to make a scatterplot\n",
    "sns.regplot(x=toronto_df[\"Population\"], y=toronto_df[\"Point_Value\"], fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Determine and map best locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Show top three locations and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 3):\n",
    "    print(\"[\" + str(i+1) + \"]\")\n",
    "    print(\"Postal Code: \" + str(toronto_df['Postal_Code'][i]))\n",
    "    print(\"Borough: \" + str(toronto_df['Borough'][i]))\n",
    "    print(\"Neighborhood: \" + str(toronto_df['Neighborhood'][i]))\n",
    "    print(\"Latitude: \" + str(toronto_df['Latitude'][i]) + \", Longitude: \" + str(toronto_df['Longitude'][i]))\n",
    "    print(\"Population: \" + str(toronto_df['Population'][i]))\n",
    "    print(\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = 43.7\n",
    "longitude = -79.3832\n",
    "\n",
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "#x = np.arange(kclusters)\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(toronto_df['Latitude'], toronto_df['Longitude'], toronto_df['Neighborhood'], [1,2,3]):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=20,\n",
    "        popup=label,\n",
    "        color='orange',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
